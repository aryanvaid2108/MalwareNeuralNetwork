{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CountFrequency(my_list): \n",
    "    # Creating an empty dictionary\n",
    "    freq = {} \n",
    "    for item in my_list: \n",
    "        if (item in freq): \n",
    "            freq[item] += 1\n",
    "        else: \n",
    "            freq[item] = 1\n",
    "    return freq\n",
    "\n",
    "my_list = [] \n",
    "filepath = '/Users/aryan/Desktop/Midterm-185C/myfile.txt'\n",
    "with open(filepath) as fp:\n",
    "   line = fp.readline()\n",
    "   cnt = 1\n",
    "   while line:\n",
    "        line = fp.readline()\n",
    "        my_list.append(line.rstrip('\\n'))\n",
    "        cnt += 1\n",
    "if(my_list[-1]) == \"\":\n",
    "    del my_list[-1]\n",
    "\n",
    "# Driver function \n",
    "if name == \"main\": \n",
    "    total_lines = cnt\n",
    "    freq={}\n",
    "    freq=CountFrequency(my_list) \n",
    "    for key, value in freq.items(): \n",
    "        freq[key] = (value/total_lines)*100\n",
    "    for key, value in freq.items(): \n",
    "        print ((key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "mnist_dataset, mnist_info = tfds.load(name = 'mnits', with_info=True, as_aupervised = True)\n",
    "mnist_train, mnist_test = mnist_dataset['train'],mnist_dataset['test']\n",
    "num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/*****\n",
    "Malicia (.txt Opcodes) - zbot: \n",
    "Malicia (.txt Opcodes) - zeroaccess: 1,310 files\n",
    "\n",
    "'D:/VCS/MalwareNeuralNetwork/00b196f09c1901bdd0d3037eaf43e2df2c03c072.asm.txt'\n",
    "*****/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balancing the dataset\n",
    "num_one_tragets = int(np.sum(targets_all)) # count how many targets are 1\n",
    "zero_targets_counter = 0 # counter for target 0\n",
    "\n",
    "indices_to_remove = [] # remove extra input/target pairs for balance \n",
    "\n",
    "# count the number of targets 0, when get same amount of target 1 and 0, make entries where target is zero\n",
    "for i in range(targets_all.shape[0]):\n",
    "        if targets_all[i] == 0:\n",
    "            zero_targets_counter +=1\n",
    "            if zero_targets_counter > cnum_one_targets:\n",
    "                indices_to_remove.append(i)\n",
    "\n",
    "unscaled_inputs_equal_priors = np.delete(unscaled_inputs_all,indiced_to_remove, axis = 0)\n",
    "targets_equal_priors = np.delete(targets_all, indices_to_remove, axis = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate into validation / traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3-TensorFlow2",
   "language": "python",
   "name": "python3-tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
