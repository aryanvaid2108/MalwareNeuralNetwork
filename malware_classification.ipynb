{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "import operator\n",
    "import itertools\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_Per_Family={}\n",
    "def Reset():\n",
    "    freq_Per_Family={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CountFrequency(my_list): \n",
    "    # Creating an empty dictionary  \n",
    "    freq = {} \n",
    "    \n",
    "    # Updating the value of the count if the operation exists \n",
    "    for item in my_list: \n",
    "        if (item in freq): \n",
    "            freq[item] += 1\n",
    "    # Adding the operation to the dictionary if it doesn't exist \n",
    "        else: \n",
    "            freq[item] = 1\n",
    "\n",
    "    for item in my_list: \n",
    "        if (item in freq_Per_Family): \n",
    "            freq_Per_Family[item] += 1\n",
    "    # Adding the operation to the dictionary if it doesn't exist \n",
    "        else: \n",
    "            freq_Per_Family[item] = 1\n",
    "            \n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fucntion to return a list path of all the files in a folder \n",
    "def ListOffiles(path):\n",
    "    dirListing = os.listdir(path)\n",
    "    #Reducing the sample size /2 \n",
    "    dirListing = os.listdir(path)\n",
    "    length = len(dirListing)\n",
    "    middle_index = length//2\n",
    "    dirListing=dirListing[:middle_index]\n",
    "    return dirListing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetFrequencies(path):\n",
    "    list_Of_Dict_Each_Family =[]\n",
    "    listOfFiles = ListOffiles(path)\n",
    "    \n",
    "    # Iterating over all files \n",
    "    for items in listOfFiles:\n",
    "        if items.endswith('.txt'):\n",
    "            filepath = path + '/' + items\n",
    "            my_list = [] \n",
    "            #Open the cuurent file\n",
    "            with open(filepath) as fp:\n",
    "                line = fp.readline()\n",
    "                cnt = 1\n",
    "                while line:\n",
    "                    line = fp.readline()\n",
    "                    #Store the operation in the line to a list\n",
    "                    my_list.append(line.rstrip('\\n'))\n",
    "                    cnt += 1\n",
    "            #Delete last element if it is empty i.e empty last line\n",
    "            if(my_list[-1]) == \"\":\n",
    "                del my_list[-1]\n",
    "            total_lines = cnt  \n",
    "            #Count frequency of each operation in the file\n",
    "            freq_Per_File={}\n",
    "            freq_Per_File=CountFrequency(my_list)\n",
    "            #Find percentage from the counted frequencies \n",
    "            for key, value in freq_Per_File.items(): \n",
    "                freq_Per_File[key] = (value/total_lines)\n",
    "            list_Of_Dict_Each_Family.append(freq_Per_File) \n",
    "\n",
    "    list_inputs= Calculate_Input()\n",
    "    l_list = UpdateFrequencies(list_Of_Dict_Each_Family,list_inputs)\n",
    "    return l_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UpdateFrequencies(list_Of_Dict_Each_Family,list_inputs):\n",
    "    temp_list=[]\n",
    "    size = len(list_Of_Dict_Each_Family)\n",
    "    for k in range (0,size,1):\n",
    "        temp_dict={}\n",
    "        Misc_sum = 0\n",
    "        for key,value in list_Of_Dict_Each_Family[k].items(): \n",
    "            if (key in list_inputs): \n",
    "                temp_dict.update({key:value})\n",
    "            else:\n",
    "                Misc_sum+=value   \n",
    "        temp_dict.update({\"Misc\":Misc_sum})\n",
    "\n",
    "        #Adding 0 to files which don't have all the 'input list' elements\n",
    "        for items in list_inputs:\n",
    "            if items not in temp_dict.keys():\n",
    "                temp_dict.update({items:0})\n",
    "        d={}\n",
    "        for key in sorted(temp_dict.keys()):\n",
    "            d.update({key:temp_dict[key]})\n",
    "        temp_list.append(d)\n",
    "    return temp_list,list_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Calculate_Input():\n",
    "    input_dict=[]\n",
    "    list_inputs=[]\n",
    "    #Sort in decending order\n",
    "    dict(sorted(freq_Per_Family.items(), key=operator.itemgetter(1),reverse=True))\n",
    "    temp_sum=0\n",
    "    #Temp dictionary to calulate no. of occurences of Misc operations \n",
    "    temp_dict = {k: freq_Per_Family[k] for k in list(freq_Per_Family)[29:]}\n",
    "    for key,value in temp_dict.items(): \n",
    "        temp_sum+=int(value)\n",
    "    # Temp input dictionary with no. of occurences of 29 most common operations\n",
    "    input_dict = {k: freq_Per_Family[k] for k in list(freq_Per_Family)[:29]}\n",
    "    # Input dictionaries with no. of occurences of most 29 common operations + Misc (All remaining operations)\n",
    "    input_dict.update({\"Misc\" : temp_sum})\n",
    "    #Storing the inputs in a list \n",
    "    for key,values in input_dict.items(): \n",
    "        list_inputs.append(key)\n",
    "    return list_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1         2         3         4         5         6   \\\n",
      "0     0.241150  0.018805  0.088496  0.012168  0.001106  0.004425  0.003319   \n",
      "1     0.251174  0.004695  0.057121  0.009390  0.002347  0.000000  0.003130   \n",
      "2     0.251174  0.004695  0.057121  0.009390  0.002347  0.000000  0.003130   \n",
      "3     0.183468  0.000000  0.084677  0.002016  0.000000  0.000000  0.000000   \n",
      "4     0.221154  0.008974  0.050641  0.006410  0.001923  0.002564  0.003205   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "1715  0.182163  0.011765  0.064137  0.026565  0.000000  0.000000  0.001139   \n",
      "1716  0.169109  0.012821  0.062271  0.021673  0.000000  0.000000  0.000305   \n",
      "1717  0.209730  0.018397  0.040474  0.027800  0.000136  0.000273  0.000136   \n",
      "1718  0.196881  0.013526  0.036070  0.027428  0.000000  0.000000  0.000000   \n",
      "1719  0.201583  0.023466  0.038733  0.028131  0.000000  0.000000  0.000141   \n",
      "\n",
      "            7         8         9   ...        21        22        23  \\\n",
      "0     0.002212  0.023230  0.009956  ...  0.014381  0.003319  0.129425   \n",
      "1     0.000000  0.019562  0.010172  ...  0.016432  0.000000  0.112676   \n",
      "2     0.000000  0.019562  0.010172  ...  0.016432  0.000000  0.112676   \n",
      "3     0.000000  0.014113  0.000000  ...  0.000000  0.000000  0.203629   \n",
      "4     0.000641  0.016667  0.012179  ...  0.014103  0.000000  0.091026   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "1715  0.000000  0.068311  0.017078  ...  0.019734  0.000000  0.098672   \n",
      "1716  0.000611  0.057692  0.014347  ...  0.014042  0.000000  0.082112   \n",
      "1717  0.000000  0.026301  0.005587  ...  0.054511  0.000000  0.080948   \n",
      "1718  0.000000  0.032313  0.002254  ...  0.057111  0.000000  0.074018   \n",
      "1719  0.000283  0.026859  0.003675  ...  0.055980  0.000000  0.082980   \n",
      "\n",
      "            24        25        26        27        28        29  30  \n",
      "0     0.002212  0.014381  0.034292  0.002212  0.009956  0.017699   0  \n",
      "1     0.000782  0.007825  0.021909  0.000782  0.014085  0.015649   0  \n",
      "2     0.000782  0.007825  0.021909  0.000782  0.014085  0.015649   0  \n",
      "3     0.000000  0.000000  0.024194  0.000000  0.000000  0.018145   0  \n",
      "4     0.001282  0.012179  0.025000  0.000641  0.021795  0.009615   0  \n",
      "...        ...       ...       ...       ...       ...       ...  ..  \n",
      "1715  0.001518  0.001518  0.006452  0.003036  0.005693  0.074763   1  \n",
      "1716  0.000611  0.002137  0.007021  0.000000  0.009463  0.078144   1  \n",
      "1717  0.000273  0.001363  0.005451  0.013491  0.001772  0.091851   1  \n",
      "1718  0.000000  0.000000  0.004697  0.018223  0.000000  0.107834   1  \n",
      "1719  0.000141  0.000283  0.004382  0.014984  0.000707  0.095844   1  \n",
      "\n",
      "[1720 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "#Path of the 1st directory containing all the malware samples\n",
    "# path1 =\"/Users/aryan/Desktop/MalwareNeuralNetwork-master/zbot\"\n",
    "path1 = \"/Users/ian/Documents/GitHub/MalwareNeuralNetwork/zbot\"\n",
    "list_Of_Dict_Family_1,list_inputs= GetFrequencies(path1)\n",
    "Reset()\n",
    "path2 = \"/Users/ian/Documents/GitHub/MalwareNeuralNetwork/zeroaccess\"\n",
    "# path2 = \"/Users/aryan/Desktop/MalwareNeuralNetwork-master/zeroaccess\"\n",
    "list_Of_Dict_Family_2,list_inputs= GetFrequencies(path2)\n",
    "\n",
    "sorted_list=sorted(list_inputs)\n",
    "sorted_list.append(\"Target\")\n",
    "\n",
    "with open('malware.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "#         writer.writerow(sorted_list)\n",
    "    lst=[]\n",
    "    size=len(list_Of_Dict_Family_1)\n",
    "    for k in range (0,size,1):\n",
    "        for key,values in list_Of_Dict_Family_1[k].items(): \n",
    "            lst.append(values)\n",
    "        lst.append(\"0\")\n",
    "        writer.writerow(lst)\n",
    "        lst=[]\n",
    "    size=len(list_Of_Dict_Family_2)\n",
    "    lst=[]\n",
    "    #Family 2\n",
    "    for k in range (0,size,1):\n",
    "        for key,values in list_Of_Dict_Family_2[k].items(): \n",
    "            lst.append(values)\n",
    "        lst.append(\"1\")\n",
    "        writer.writerow(lst)\n",
    "        lst=[]\n",
    "\n",
    "    df = pd.read_csv('malware.csv',header=None)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# preprocessing the data\n",
    "raw_cvs_data = np.loadtxt('malware.csv',delimiter=',')\n",
    "#All except last column \n",
    "unscaled_inputs_all = raw_cvs_data[:-1]\n",
    "#Last column is the target\n",
    "targets_all = raw_cvs_data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balancing the dataset\n",
    "num_one_targets = int(np.sum(targets_all)) # count how many targets are 1\n",
    "zero_targets_counter = 0 # counter for target 0\n",
    "\n",
    "indices_to_remove = [] # remove extra input/target pairs for balance \n",
    "\n",
    "# count the number of targets 0, when get same amount of target 1 and 0, make entries where target is zero\n",
    "for i in range(targets_all.shape[0]):\n",
    "        if targets_all[i] == 0:\n",
    "            zero_targets_counter +=1\n",
    "            if zero_targets_counter > num_one_targets:\n",
    "                indices_to_remove.append(i)\n",
    "\n",
    "unscaled_inputs_equal_priors = np.delete(unscaled_inputs_all,indices_to_remove, axis = 0)\n",
    "\n",
    "targets_equal_priors = np.delete(targets_all, indices_to_remove, axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize the input using sklearn\n",
    "scaled_inputs = preprocessing.scale(unscaled_inputs_equal_priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle the data \n",
    "shuffled_indices = np.arange(scaled_inputs.shape[0])\n",
    "np.random.shuffle(shuffled_indices) #shuffle pairs\n",
    "\n",
    "shuffled_inputs = scaled_inputs[shuffled_indices]\n",
    "shuffled_targets = targets_equal_priors[shuffled_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508.0 1042 0.4875239923224568\n",
      "74.0 130 0.5692307692307692\n",
      "69.0 131 0.5267175572519084\n"
     ]
    }
   ],
   "source": [
    "# splitting data\n",
    "samples_count = shuffled_inputs.shape[0]\n",
    "\n",
    "# number of samples in each part\n",
    "# |training|validation|testing| 80-10-10\n",
    "train_samples_count = int(0.8 * samples_count)\n",
    "validation_samples_count = int(0.1 *samples_count)\n",
    "test_samples_count = samples_count - train_samples_count - validation_samples_count\n",
    "\n",
    "train_inputs = shuffled_inputs[:train_samples_count]\n",
    "train_targets = shuffled_targets[:train_samples_count]\n",
    "\n",
    "validation_inputs = shuffled_inputs[train_samples_count:train_samples_count + validation_samples_count]\n",
    "validation_targets = shuffled_targets[train_samples_count:train_samples_count + validation_samples_count]\n",
    "\n",
    "test_inputs = shuffled_inputs[train_samples_count + validation_samples_count:]\n",
    "test_targets = shuffled_targets[train_samples_count + validation_samples_count:]\n",
    "\n",
    "print(np.sum(train_targets), train_samples_count, np.sum(train_targets)/train_samples_count)\n",
    "print(np.sum(validation_targets), validation_samples_count, np.sum(validation_targets)/validation_samples_count)\n",
    "print(np.sum(test_targets), test_samples_count, np.sum(test_targets)/test_samples_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('malware_data_train', inputs=train_inputs, targets=train_targets)\n",
    "np.savez('malware_data_validation', inputs=validation_inputs, targets=validation_targets)\n",
    "np.savez('malware_data_test', inputs=test_inputs, targets=test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
